<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Analyze Data</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">assignPOP</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="start.html">Get Started</a>
</li>
<li>
  <a href="analyze.html">Analyze Data</a>
</li>
<li>
  <a href="visualize.html">Visualize Results</a>
</li>
<li>
  <a href="examples.html">Examples</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/alexkychen/assignPOP">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Analyze Data</h1>

</div>


<p>Here, we demonstrate how to prepare, import, and analyze data. To evaluate baseline data, we use simulated genetic and non-genetic datasets to demonstrate how integrated data could outperform each data type used independently. The graphical results are shown on <a href="http://alexkychen.github.io/assignPOP/visualize.html">Visualize Results</a> page. In this page, we focus on how and which functions are used to import data, reduce low variacne loci, integrate data, perform resampling cross-validations, calculate assignment accuracy, and identify informative loci. We also demonstrate how to perform a one-time assignment test on individuals of unknown origins using baseline data.</p>
<hr />
<div id="evaluate-baseline-data" class="section level2">
<h2>Evaluate baseline data</h2>
<p>Baseline data are individuals and their features (e.g., genetic loci, non-genetic measurements) collected from known or source populations. We will demonstrate how to prepare and import three different data types: genetic, integrated, and non-genetic, but will only use the genetic data to show the scripts of performing resampling cross-validation.</p>
<div id="prepare-and-import-genetic-data" class="section level3">
<h3>Prepare and import genetic data</h3>
<p>assignPOP accepts genetic data in GENEPOP<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> and STRUCTURE<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> formats. Both formats can be either diploid or haploid data.</p>
<p>When importing a GENEPOP file, <a href="http://genepop.curtin.edu.au/help_input.html">two forms</a> of GENEPOP can be read into R using the function <code>read.Genepop()</code>. Populatino names can be specified using the argument <code>pop.names</code>, and the order of population names should follow the group order in your GENEPOP file<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. These population names can be used to customize the assignment accuracy plot later on. Use the argument <code>haploid</code> to specify your data type (e.g., use <code>haploid=F</code> for diploid data).</p>
<pre class="r"><code>genin &lt;- read.Genepop( &quot;simGenepop.txt&quot;, pop.names=c(&quot;pop_A&quot;,&quot;pop_B&quot;,&quot;pop_C&quot;), haploid = FALSE)</code></pre>
<p>The example input file, <a href="https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/simGenepop.txt"><em>simGenepop.txt</em></a>, contains <strong>three</strong> simulated populations (or subpopulations) and each population has 30 individuals by 1,000 SNP loci. Depending on the data size, the importing process may take a few secnods to minutes. A progress bar will be running while importing the data. After importing the file, you should see the following message printed in your R console. Use the information to double check whether your data were correctly imported.</p>
<pre><code>## ############### assignPOP v1.x.x ###############
## 
## A GENEPOP format file was successfully imported!
## 
## Imported Data Info: 90 obs. by 1000 loci (diploid)
## Number of pop:3
## Number of inds (pop_A): 30
## Number of inds (pop_B): 30
## Number of inds (pop_C): 30
## 
## DataMatrix: 90 rows by 2001 columns, with 2000 allele variables
## 
## Data output in a list comprising the following three elements:
## YOUR_LIST_NAME$DataMatrix
## YOUR_LIST_NAME$SampleID
## YOUR_LIST_NAME$LocusName</code></pre>
<p>When importing a STRUCTURE file, use the function <code>read.Structure()</code>, and specify the data type using the argument <code>haploid</code>. Your Structure file should include locus names (each name separated by whitespace or tab) on the first row as the column name. The first column should be your sample ID; the second column is population label and the rest of columns are genetic data. It does not matter whether your file has column names for sample ID and/or population label.</p>
<pre class="r"><code>strin &lt;- read.Structure( &quot;simStructure.txt&quot;, haploid = TRUE)</code></pre>
<p>After importing your STRUCTURE file, you will also see the printed message in the console. For the sake of simplicity, we only use the GENEPOP dataset to demonstrate the rest of analyses.</p>
<p><strong>Missing data and homozygosity.</strong> If an locus has missing alleles or is homomzygous across all individuals in the dataset, the locus will be automatically removed.</p>
<p><br></p>
</div>
<div id="remove-low-variance-loci-optional" class="section level3">
<h3>Remove low variance loci (optional)</h3>
<p>When analyzing genetic data, you can remove low variance loci<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> across the dataset for further analyses. The default of variance threshold is 0.95, meaning that a locus will be removed from the dataset if its major allele occurs in over 95% of individuals across the populations.</p>
<p>To remove low variance loci, use the following function and provide a new return object name (<code>genin_rd</code> in this case) :</p>
<pre class="r"><code>genin_rd &lt;- reduce.allele(genin, p = 0.95)</code></pre>
<p>After entering the code, R console should print the following message.</p>
<pre><code>## New data matrix has created! :)
## New DataMatrix size: 90 rows by 1387 columns
## 614 columns (alleles) have been removed
## 693 loci remain</code></pre>
<p>In our example, 307 low variance loci<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> were removed, leaving 693 loci in the new data set, which will be used in further analyses.</p>
<p><br></p>
</div>
<div id="concatenate-genetic-and-non-genetic-data" class="section level3">
<h3>Concatenate genetic and non-genetic data</h3>
<p>Concatenating genetic and non-genetic data is one of the novel features in this package. After importing your GENEPOP file, you can use the function <code>compile.data()</code> to concatenate a non-genetic dataset and the genetic matrix returned from either <code>read.Genepop()</code>, <code>read.Structure()</code>, or <code>reduce.allele()</code>. Your non-genetic data should be saved in a .csv file (elements separated by commas) or table-like text file (elements separated by spaces) in which the first column must be sample IDs that match the IDs in your GENEPOP or STRUCTURE file, and the rest of columns are non-genetic data, whether it is numeric or categorical. If a sample ID exists in only one of the data types, the individual will be ignored in the new integrated data.</p>
<p>To concatenate datasets, use the following function and provide a new return object name (<code>comin</code> in this case):</p>
<pre class="r"><code>comin &lt;- compile.data(genin_rd, &quot;morphData.csv&quot;)</code></pre>
<p>The above <a href="https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/morphData.csv"><em>morphData.csv</em></a> file has the same individuals as the <a href="https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/simGenepop.txt"><em>simGenepop.txt</em></a> and it contains 4 numeric variables (morphometric measurements) for each individual. After executing the function, it will prompt the following message and wait for your answer to verify the data type (numeric or categorical).</p>
<pre><code>## Import a .CSV file.
## 4 additional variables detected.
## Checking variable data type...
##  D1.2(integer)  D2.3(integer)  D3.4(integer)  D1.4(integer)
##  Are they correct? (enter Y/N):</code></pre>
<p>If a variable is categorical data, it will automatically convert it to new <a href="https://en.wikipedia.org/wiki/Dummy_variable_(statistics)">dummy variables</a> using <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/model.matrix.html">model.matrix()</a> so that the categorical data can be quantified for further analyses. If your data type was incorrectly identified, simply enter <strong>N</strong> and then follow the prompted dialogue to change your data type. If your data type is correctly identified (entry is <strong>Y</strong> in this example), then it will print the following message.</p>
<pre><code>## New data set created!!
## It has 90 observations by 1391 variables
## including 693 loci(1386 alleles) plus 4 additional variables(4 columns)</code></pre>
<p>Now the integrated data (693 SNP loci plus 4 morphometric measurements) matrix is saved in the return object named <code>comin</code>.</p>
<p><br></p>
</div>
<div id="prepare-and-import-non-genetic-data" class="section level3">
<h3>Prepare and import non-genetic data</h3>
<p>In addition to analyzing genetic-only or integrated data, you can perform the same analysis on non-genetic data so that you could compare the assignment results between data types. A non-genetic data set (collected from source populations) should include 1) sample IDs in the first column, 2) population label<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> in the <strong>last</strong> column, and 3) non-genetic data in columns between the sample ID and population label columns. The file should be saved in a .csv (comma delimited) or table-like text file that can be read into R using R basic functions <code>read.csv()</code> or <code>read.table()</code>. For example, if you are going to perform assignment test using the sample morphometric data (<a href="https://raw.githubusercontent.com/alexkychen/assignPOP/master/inst/extdata/morphData.csv"><em>morphData.csv</em></a>) provided in the pakcage, you would need to add a population column after the existing last column. It can be edited manually (e.g., using Excel) or by R scripts (see below).</p>
<pre class="r"><code>#Import morphometric data containing sample IDs and features
morphdf &lt;- read.csv( &quot;morphData.csv&quot;, header=TRUE )
#Create a string vector for population label (repeat each name for 30 individuals)
pop_label &lt;- c( rep(&quot;pop_A&quot;, 30), rep(&quot;pop_B&quot;, 30), rep(&quot;pop_C&quot;, 30) ) 
#Add the pop_label to the last column; &#39;morphdf_pop&#39; is a data frame with population label in the last column
morphdf_pop &lt;- cbind(morphdf, pop_label)</code></pre>
<p>Now the non-genetic (morphometric) data with its population label is saved in the object <code>morphdf_pop</code>.</p>
<p><br></p>
</div>
<div id="performassignment" class="section level3">
<h3>Perform resampling cross-validation</h3>
<p>We provide two resampling cross-validation methods, <a href="http://stats.stackexchange.com/questions/51416/k-fold-vs-monte-carlo-cross-validation">Monte-Carlo and <em>K</em>-fold cross-validations</a>, to evaluate baseline data. Monte-Carlo cross-validation helps estimate the mean and variance of assignment accuracy through resampling random training individuals; <em>K</em>-fold cross-validation helps determine membership probability across all individuals through using one group as test individuals and the remaining K-1 groups as training individuals (hence every individual is tested once).</p>
<p>When analyzing genetic data (genetic-only or integrated), users can specify what proportions of loci should be used as training loci, and determine whether the proportion of loci is chosen either randomly or based on locus <em>F<sub>ST</sub></em> estimated within training individuals. This helps evaluate whether using a subset of loci performs as well as using all loci. Most informative loci also can be identified via the function <code>check.loci</code> (see <a href="#informloci">Identify informative loci</a>)</p>
<div id="monte-carlo-cross-validation" class="section level4">
<h4>Monte-Carlo cross-validation</h4>
<p>When performing Monte-Carlo cross-validation (<code>assign.MC()</code>), users can specify multiple proportions or multiple numbers of individuals from each population to be used as training individuals. Each combination of training individuals and features (e.g., loci or non-genetic measurements) can be resampled multiple times. For example, the code below performs Monte-Carlo cross-validation, with using 50%, 70%, and 90% of random individuals from each population (arg. <code>train.inds</code>) crossed by top 10%, 25%, 50% of high <em>F<sub>ST</sub></em> loci, and all loci (arg. <code>train.loci</code>, <code>loci.sample=&quot;fst&quot;</code>) as training data. Each combination of training data is resampled 30 times (arg. <code>iterations</code>). As a result, it performs a total of 360 assignment tests (3 levels of training individuals by 4 levels of training loci by 30 iterations).</p>
<pre class="r"><code>assign.MC(genin_rd, train.inds=c(0.5, 0.7, 0.9), train.loci=c(0.1, 0.25, 0.5, 1), 
          loci.sample=&quot;fst&quot;, iterations=30, dir=&quot;Result-folder/&quot;, model=&quot;svm&quot; )</code></pre>
<p>To use certain numbers, rather than proportions, of individuals from each population as training data, enter positive integers in the argument <code>train.inds</code>(e.g., <code>train.inds = c(10, 20, 30)</code>). The reason of using equal number of traininig individuals from each population is that it can avoid biases due to unbalanced population sample size<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>, <a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>.</p>
<p>If you are analyzing non-genetic data alone, the arguments, <code>train.loci</code> and <code>loci.sample</code>, will be automatically ignored.</p>
<p>Results of assignment tests will be saved in text files under a folder created via the argument <code>dir</code>. The above example creates a folder named “Result-folder.” And be sure to include a forward slash (<code>/</code>) at the end of the folder name.</p>
<p>In addition, you can use the argument <code>model</code> to select a classification method for prediction. In the above example, the <a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machine (SVM)</a> algorithm is used. Other SVM related arguments, <code>svm.kernel</code> and <code>svm.cost</code>, can be specified to fine tune the predictive model. See <a href="https://cran.r-project.org/web/packages/e1071/index.html">e1071</a> package for details about SVM. Other classification methods, including <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis">LDA</a>, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes</a>, <a href="https://en.wikipedia.org/wiki/Decision_tree">decision tree</a>, and <a href="https://en.wikipedia.org/wiki/Random_forest">random forest</a>, can be specified to build predictive models. Type <code>?assign.MC</code> to see more details.</p>
</div>
<div id="k-fold-cross-validation" class="section level4">
<h4><em>K</em>-fold cross validation</h4>
<p>Because Monte-Carlo cross-validation that repeats assignment tests through resampling random individuals does not guarantee every individual was tested, estimating membership probability of all individuals in this way could be problematic. To estimate membership probability, we introduce <em>K</em>-fold cross-validation (<code>assign.kfold()</code>) in which individuals from each population are divided into K groups. One of the K groups is tested by the predictive model built based on the remaining K-1 groups. Such an assignment test repeats until every group was tested. Multiple K values can be specified (arg. <code>k.fold</code>) in one analysis as follows.</p>
<pre class="r"><code>assign.kfold(genin_rd, k.fold=c(3, 4, 5), train.loci=c(0.1, 0.25, 0.5, 1), 
             loci.sample=&quot;random&quot;, dir=&quot;Result-folder2/&quot;, model=&quot;lda&quot; )</code></pre>
<p>The above example divides individuals from each population into 3, 4, or 5 groups (or folds). In each fold, 10%, 25%, and 50% of random loci (<code>loci.sample = &quot;random&quot;</code>) as well as all loci were sampled as training data. As a result, the <em>K</em>-fold cross-validation performs a total of 48 assignment tests (48 = (3+4+5) folds * 4 levels of training loci).</p>
<p>Similarly, one of the classification methods can be specified to build the predictive models. Linear Discriminant Funtion (<code>model=&quot;lda&quot;</code>) was used in the above example.</p>
<p><strong>Parallel computing.</strong> When performing resampling cross-validation, by default, it uses your available CPU cores/threads (N) minus one for parallel analyses such that N-1 assignment tests are performed simultaneously (assuming your computer’s CPU is multi-core). To change the number of cores/threads to be used, simply specify a number for the argument <code>processors</code> (e.g., <code>processors = 2</code> for using two cores/threads).</p>
<p>Depending on the size of your dataset, running <code>assign.MC()</code> may take a few minutes to hours, whereas <code>assign.kfold()</code> should spend less time because it usually performs fewer tests. You can monitor the analysis status by counting the output files in the result folder.</p>
<p><br></p>
</div>
</div>
<div id="accuracy" class="section level3">
<h3>Calculate assignment accuracy</h3>
<p>When resampling cross-validations are done, you can calculate assignment accuracies using the following functions.</p>
<pre class="r"><code>accuMC &lt;- accuracy.MC(dir = &quot;Result-folder/&quot;) #Use this function for Monte-Carlo cross-validation results
accuKF &lt;- accuracy.kfold(dir = &quot;Result-folder2/&quot;) #Use this function for K-fold cross-validation results</code></pre>
<p>The functions read through each assignment result in the designated folder (arg. <code>dir</code>) and calculate the assignment accuracies for overall and individual populations. The results will be saved in a text file named <strong>Rate_of…txt</strong>, and a return object (<code>accuMC</code> and <code>accuKF</code> in the above examples). The output text file also can be read into R using the basic function <code>read.table()</code> as follows.</p>
<pre class="r"><code>accuMC &lt;- read.table(&quot;Rate_of....txt&quot;, header=T)</code></pre>
<p>Compared with <em>K</em>-fold cross-validation, the results of Monte-Carlo cross-validation, with reasonable iterations (e.g., resample &gt; 30 times), are more suitable for estimating mean and variance of assignment accuracy. As such, using the function <code>accuracy.MC()</code> for Monte-Carlo results is more useful than using <code>accuracy.kfold()</code>. The results generated by <code>accuracy.MC()</code> (or <code>accuracy.kfold()</code>) can be visualized in an assignment accuracy plot; the results generated by the <em>K</em>-fold cross-validation (<code>assign.kfold()</code>) can be directly used to make a membership probability plot. See <a href="http://alexkychen.github.io/assignPOP/visualize.html">Visualize Results</a> page for more details.</p>
<p><br></p>
</div>
<div id="informloci" class="section level3">
<h3>Identify informative loci</h3>
<p>In some cases, using a subset of high <em>F<sub>ST</sub></em> loci may produce similar assignment accuracy with using all available loci. Identification of these loci not only could help reduce time and cost in preparing samples in the future but also could help identify loci that might be associated with functional genes.</p>
<p>The function <code>check.loci()</code> reads through each training locus file associated with the assignment test, counts the frequency of occurrence of each locus, and writes the results to a text file.</p>
<pre class="r"><code>check.loci(dir = &quot;Result-folder/&quot;, top.loci = 20)</code></pre>
<p>This function should only be used for the cross-validation results based on resampling high <em>F<sub>ST</sub></em> training loci (<code>loci.sample = &quot;fst&quot;</code>) in the <code>assign.MC()</code> analysis.</p>
<p>By default, this function outputs top 20 loci - most frequently used high <em>F<sub>ST</sub></em> training loci across your assignment tests, but an arbitrary number can be specified in the argument <code>top.loci</code>.</p>
<p>When the function is executed, as shown below, you will be prompted to choose which assignment results you would like to check. The options are the groups of different proportions or numbers of training individuals that you specified in the argument <code>train.inds</code> of the function <code>assign.MC()</code>.</p>
<pre><code>## 3 levels of training individuals are found.
## Which levels would you like to check? (separate levels by a whitespace if multiple)
## Options: 0.5, 0.7, 0.9, or all
## enter here: (You will enter your answer here)</code></pre>
<p>Because a locus <em>F<sub>ST</sub></em> value estimated based on a training set likely varies among subsets of training individuals, we recommend running the function <code>check.loci()</code> across all levels of proportions or numbers of training individuals to evaluate if the loci consistently are those high <em>F<sub>ST</sub></em> loci. If so, then they could be recognized as truly informative loci (high <em>F<sub>ST</sub></em> is not due to sampling artifacts).</p>
<p>The output file (<em>High_Fst_Locus_Freq.txt</em>) includes a list of locus names ordered by <em>F<sub>ST</sub></em> value (highest <em>F<sub>ST</sub></em> in the top row). The number in parentheses right after each locus name indicates the number of tests that locus appeared in that rank. A snapshot of output content is shown below.</p>
<pre><code>Loci occur in top 20 high Fst across all training data
top.1(1): Locus_171(360), 
top.2(1): Locus_442(360), 
top.3(1): Locus_475(360), 
top.4(1): Locus_481(360), 
top.5(1): Locus_696(360), 
top.6(1): Locus_697(360), 
top.7(1): Locus_729(360), 
top.8(1): Locus_745(360), 
top.9(1): Locus_812(360), 
top.10(1): Locus_941(360), 
top.11(1): Locus_992(360), 
top.12(5): Locus_113(248), Locus_114(76), Locus_115(24), Locus_320(8), Locus_139(4), 
top.13(7): Locus_245(240), Locus_181(72), Locus_147(24), Locus_115(8), Locus_560(8), Locus_137(4), Locus_160(4), </code></pre>
<p>The above results show that the top.1-top.11 loci are the top 11 highest <em>F<sub>ST</sub></em> loci are across all 360 tests. Five loci (<code>top.12(5): Locus_113, Locus_114, Locus_115, Locus_320, and Locus_139</code>) appear to be the 12th highest <em>F<sub>ST</sub></em> locus across the tests, and <code>Locus_113</code> occurs most frequently (248 out of 360 tests) in this rank.</p>
<hr />
</div>
</div>
<div id="predict-sources-of-unknown-individuals" class="section level2">
<h2>Predict sources of unknown individuals</h2>
<p>After baseline data were evaluated through resampling cross-validation and the assignment results are satisfactory, you could use the entire baseline data to build a predictive model and perform assignment tests on individuals of unknown origins to predict their source populations. Here we describe how to prepare and import files for different data types and perform the assignment test using the function <code>assign.X()</code>.</p>
<div id="prepare-and-import-data-of-unknown-individuals" class="section level3">
<h3>Prepare and import data of unknown individuals</h3>
<p>To predict sources of unknown individuals, users should save the data of unknown individuals in another file, and import it into R using the same functions as we used for the baseline data.</p>
<p>To import genetic data of unknown individuals, the data should also be saved in GENEPOP format with only one group, meaning the data will have only one ‘pop’ label. To read the file, use the function <code>read.Genepop</code> and ignore the argument <code>pop.names</code> as follows.</p>
<pre class="r"><code># Import a GENEPOP file containing unknown individuals. Make sure to use a different return object name from the one returnd from your baseline data 
genin_unknown &lt;- read.Genepop( &quot;simGenepopX.txt&quot; )</code></pre>
<p>You can also concatenate genetic and non-genetic data using the function <code>compile.data</code> as follows.</p>
<pre class="r"><code>comin_unknown &lt;- compile.data(genin_unknown, &quot;OtherFeautures.csv&quot;)</code></pre>
<p>The non-genetic data of unknown individuals (<strong>OtherFeatures.csv</strong>) should also have the identical sample IDs as the genetic data (<strong>simGenepopX.txt</strong>), and the sample IDs should be saved in the first column in the file.</p>
<p>If you are analyzing non-genetic data, use R basic functions, <code>read.csv()</code> or <code>read.table()</code>, to import your file.</p>
<pre class="r"><code>#Import non-genetic data containing sample IDs and features
nongen_unknown &lt;- read.csv( &quot;OtherFeatures.csv&quot;, header=TRUE )</code></pre>
<p><br></p>
</div>
<div id="perform-assignment-test-on-unknown-individuals" class="section level3">
<h3>Perform assignment test on unknown individuals</h3>
<p>After importing training (baseline) and test (unknown individuals) data, the assignment test can be performed using the function <code>assign.X</code>. Make sure that your training and test data have the same data type and feature names. Use the argument <code>X1</code> to specify the training data; <code>X2</code>, the test data.</p>
<pre class="r"><code># 1.Perform assignment test using genetic data and naive Bayes
assign.X( x1=genin, x2=genin_unknown, dir=&quot;Result-folder3/&quot;, model=&quot;naiveBayes&quot;)

# 2.Perform assignment test using integrated data and decision tree
assign.X( x1=comin, x2=comin_unknown, dir=&quot;Result-folder4/&quot;, model=&quot;tree&quot;)

# 3.Perform assignment test uisng non-genetic data and random forest
assign.X( x1=morphdf_pop, x2=nongen_unknown, dir=&quot;Result-folder5/&quot;, model=&quot;randomForest&quot;)

# Use `?assign.X` to see other argument settings.</code></pre>
<p>The assignment result will be saved in a text file named <em>AssignmentResult.txt</em> under the designated folder. This file includes sample IDs of your unknown individuals, predicted populations and the probabilities. When the assignment is done, it will prompt a message asking you whether a membership probability plot should be generated. You can enter <strong>Y</strong> to visualize the results right away.</p>
<hr />
</div>
</div>
<div id="data-process" class="section level2">
<h2>Data process</h2>
<div id="pca-for-data-transformation" class="section level3">
<h3>PCA for data transformation</h3>
<p>The assignment functions, <code>assign.MC()</code>, <code>assign.kfold()</code> and <code>assign.X()</code>, use PCA for dimensionality reduction. It converts your independent variables to Principle Components and retain the PCs that have eigenvalues greater than 1 (the Kaiser-Guttman criterion) as new features (arg. <code>pca.PCs=&quot;kaiser-guttman&quot;</code>). Or, you can specify an integer in the argument <code>pca.PCs</code> (e.g., <code>pca.PCs = 10</code>) to choose a specific number of PCs to be retained.</p>
<p>The PCA will always perform on the genetic data, whether you are analyzing genetic-only or integrated data. When analyzing integrated data, you have three options to perform PCA on the data. First, you can perform PCA across all features (set arg. <code>pca.method=&quot;mixed&quot;</code>), meaning that each PC includes information of genetic and non-genetic data. This is default setting. Second, you can perform PCA on genetic and non-genetic data independently (set arg. <code>pca.method=&quot;independent&quot;</code>), meaning that your transformed data includes genetic PCs and non-genetic PCs. Third, you can choose to use original non-genetic data as features without performing PCA on them (set. arg. <code>pca.method=&quot;original&quot;</code>). This option ends up using genetic PCs and original non-genetic data to build predictive models.</p>
<p>When analyzing non-genetic data alone, you can determine whether PCA is performed on the data. You set the argument <code>pca.method=TRUE</code> to perform PCA, or <code>pca.method=FALSE</code> to not perform PCA.</p>
</div>
<div id="data-standardization" class="section level3">
<h3>Data standardization</h3>
<p>When analyzing non-genetic or integrated data, you have options to standardize (zero mean and unit variance) the independent variables or keep the original data. If non-genetic data has varying ranges of values and is not standardized, it may be problematic when one feature has a variance that is orders of magnitude larger than others, as it might make the classifier unable to learn from other features correctly. To center and scale the data, set the argument <code>scaled=TRUE</code> in the function <code>assign.MC()</code>, <code>assign.kfold()</code> or <code>assign.X()</code>. If you are analyzing genetic or genomic data, then standardization is not required because all the loci (alleles) have been converted to values between 0 and 1.</p>
<hr />
<div id="reference-and-footnotes" class="section level4">
<h4>Reference and footnotes</h4>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Rousset, F. (2008). genepop’007: A Complete Re-Implementation of the Genepop Software for Windows and Linux. <em>Molecular Ecology Resources</em> 8(1): 103–106.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Pritchard, J.K., Stephens, M. &amp; Donnelly, P. (2000). Inference of Population Structure Using Multilocus Genotype Data. <em>Genetics</em>, 155, 945–959.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>The name order in the argument <code>pop.names</code> should match the group order in your GENEPOP file. For example, the first name, <code>pop_A</code>, in <code>pop.names=c(&quot;pop_A&quot;,&quot;pop_B&quot;,&quot;pop_C&quot;)</code> is the first group (pop) of individuals in the GENEPOP. If <code>pop.names</code> is not provided, pop.<em>NUMBER</em> (e.g., pop.1, pop.2) will be used as the population name.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>A low variance locus - which has a major allele in most individuals and a minor allele in very few individuals - is unlikely useful because if an allele only occurs in the training or test data, it will not help ascertain population membership of test individuals.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>In this case, we have 614 alleles across 307 loci, meaning that every locus is biallelic (307 loci x 2 alleles = 614 alleles)<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>A column includes population names for each individual. Also be sure to include a column name in table header.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Puechmaille, S.J. (2016). The program structure does not reliably recover the correct population structure when sampling is uneven: subsampling and new estimators alleviate the problem. <em>Molecular Ecology Resources</em>, 16, 608–627<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Wang, J. (2016). The computer program Structure for assigning individuals to populations: easy to use but easier to misuse. <em>Molecular Ecology Resources</em>.<a href="#fnref8">↩</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
